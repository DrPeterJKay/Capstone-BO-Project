{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from torch.quasirandom import SobolEngine\n",
    "import botorch\n",
    "import gpytorch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will see how to use the TuRBO Bayesian Optimization tool for the capstone project. TuRBO is a BO algorithm proposed by Uber that specializes in high-dimensional problems. You can read the details of the algorithm in the paper:\n",
    "\n",
    "\n",
    "Eriksson et al., \"Scalable Global Optimization via Local Bayesian Optimization\", NeurIPS (2019). URL: https://proceedings.neurips.cc/paper/2019/file/6c990b7aca7bc7058f5e98ea909e924b-Paper.pdf\n",
    "\n",
    "For implementing the method, we will be using the Gaussian Process library GPyTorch, and the Bayesian Optimization library BoTorch. We will be loosely following the tutorial made by BoTorch's team:\n",
    "\n",
    "https://botorch.org/tutorials/turbo_1\n",
    "\n",
    "However, we will be making some modification that are case-specific for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TuRBO works by creating a Trust Region over which will focus all our optimization efforts. This works great for higher-dimensions because the search space is too large and algorithms tend to over-explore! \n",
    "\n",
    "We keep track of a 'Turbo State' that dictates the size and location of the region. The code below implements a data class that will help us keep track of the state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define a dataclass for our state\n",
    "@dataclass\n",
    "class TurboState:\n",
    "    dim: int # dimension of the problem, aka input dimension\n",
    "    batch_size: int = 1 # we could do batch optimization, but the capstone only does one query at a time\n",
    "    length: float = 0.8 # the length of the current trust region\n",
    "    length_min: float = 0.5 ** 7 # minimum length for the trust region\n",
    "    length_max: float = 1.6 # maximum length for the trust region\n",
    "    failure_counter: int = 0 # initialize counter of the number of failures to improve on the best observation\n",
    "    failure_tolerance: int = float(\"nan\")  # Note: Post-initialized\n",
    "    success_counter: int = 0 # initialize counter of the number of success to improve on the best observation\n",
    "    success_tolerance: int = 3  # Note: The original paper uses 3, this is the number of successes in a row needed to expand the region\n",
    "    best_value: float = -float(\"inf\") # best value so far, initialized to be the infimum\n",
    "    restart_triggered: bool = False \n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.failure_tolerance = math.ceil(\n",
    "            max([4.0 / self.batch_size, float(self.dim) / self.batch_size]) # number of failures needed in a row to shrink the trust region\n",
    "        )\n",
    "\n",
    "\n",
    "def update_state(state, Y_next):\n",
    "    # count if a success, otherwise a failure\n",
    "    if max(Y_next) > state.best_value + 1e-3 * math.fabs(state.best_value):\n",
    "        state.success_counter += 1\n",
    "        state.failure_counter = 0\n",
    "    else:\n",
    "        state.success_counter = 0\n",
    "        state.failure_counter += 1\n",
    "    # check if we need to expand or shrink the trust region\n",
    "    if state.success_counter == state.success_tolerance:  # Expand trust region\n",
    "        state.length = min(2.0 * state.length, state.length_max)\n",
    "        state.success_counter = 0\n",
    "    elif state.failure_counter == state.failure_tolerance:  # Shrink trust region\n",
    "        state.length /= 2.0\n",
    "        state.failure_counter = 0\n",
    "    # set the best value if we got a new observation\n",
    "    state.best_value = max(state.best_value, max(Y_next).item())\n",
    "    if state.length < state.length_min:\n",
    "        state.restart_triggered = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be very important to keep track of the state when we optimize, as we will need to make sure we keep the state updated from query to query. You can use a print statement to see the value of a state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TurboState(dim=6, batch_size=1, length=0.8, length_min=0.0078125, length_max=1.6, failure_counter=0, failure_tolerance=6, success_counter=0, success_tolerance=3, best_value=-inf, restart_triggered=False)\n"
     ]
    }
   ],
   "source": [
    "state = TurboState(dim = 6)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to record these variables after choosing a new query, and re-input, and update to the correct state when we receive new observations. An example of this will be given later. We can then define the TuRBO loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(\n",
    "    state,\n",
    "    model,  # GP model\n",
    "    X,  # Evaluated points on the domain [0, 1]^d\n",
    "    Y,  # Function values\n",
    "    batch_size = 1, # fix batch size to 1\n",
    "    n_candidates=None,  # Number of candidates for Thompson sampling\n",
    "    num_restarts=10,\n",
    "    raw_samples=512,\n",
    "    acqf=\"ts\",  # \"ei\" or \"ts\"\n",
    "):\n",
    "    assert acqf in (\"ts\")\n",
    "    assert X.min() >= 0.0 and X.max() <= 1.0 and torch.all(torch.isfinite(Y))\n",
    "    if n_candidates is None:\n",
    "        n_candidates = min(5000, max(2000, 200 * X.shape[-1]))\n",
    "\n",
    "    # Scale the trust region to be proportional to the lengthscales\n",
    "    x_center = X[Y.argmax(), :].clone()\n",
    "    weights = model.covar_module.base_kernel.lengthscale.squeeze().detach()\n",
    "    weights = weights / weights.mean()\n",
    "    weights = weights / torch.prod(weights.pow(1.0 / len(weights)))\n",
    "    tr_lb = torch.clamp(x_center - weights * state.length / 2.0, 0.0, 1.0)\n",
    "    tr_ub = torch.clamp(x_center + weights * state.length / 2.0, 0.0, 1.0)\n",
    "    # we focus only on thompson sampling as an acquisition function\n",
    "    if acqf == \"ts\":\n",
    "        dim = X.shape[-1]\n",
    "        sobol = SobolEngine(dim, scramble=True)\n",
    "        pert = sobol.draw(n_candidates)\n",
    "        pert = tr_lb + (tr_ub - tr_lb) * pert\n",
    "\n",
    "        # Create a perturbation mask\n",
    "        prob_perturb = min(20.0 / dim, 1.0)\n",
    "        mask = (\n",
    "            torch.rand(n_candidates, dim)\n",
    "            <= prob_perturb\n",
    "        )\n",
    "        ind = torch.where(mask.sum(dim=1) == 0)[0]\n",
    "        mask[ind, torch.randint(0, dim - 1, size=(len(ind),))] = 1\n",
    "\n",
    "        # Create candidate points from the perturbations and the mask        \n",
    "        X_cand = x_center.expand(n_candidates, dim).clone()\n",
    "        X_cand[mask] = pert[mask]\n",
    "\n",
    "        # Sample on the candidate points\n",
    "        # set model to evaluation mode\n",
    "        model.eval()\n",
    "        posterior_distribution = model(X_cand)\n",
    "        with torch.no_grad():  # We don't need gradients when using TS\n",
    "            posterior_sample = posterior_distribution.sample()\n",
    "            X_next_idx = torch.argmax(posterior_sample)\n",
    "            X_next = X_cand[X_next_idx]\n",
    "\n",
    "    return X_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above requires us to use a GPyTorch model as an input. A tutorial on how GPyTorch models can be used is found here: https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/Simple_GP_Regression.html\n",
    "\n",
    "Below we define our model class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the model given in the tutorial, we also add the hyper-parameter training as a method\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        # set a constant mean\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        # use a simple RBF kernel with constant scaling\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=train_x.shape[1]))\n",
    "        # set number of hyper-parameter training iterations\n",
    "        self.training_iter = 2000\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this notebook, we will optimize the function:\n",
    "\n",
    "$$f(x_1, x_2, x_3, x_4, x_5, x_6) = x_3 * \\sin(x_1) * \\cos(x_2) + x_4 * x_5 - x_6 * x_5^2$$\n",
    "\n",
    "We will create an initial data set at random.\n",
    "\n",
    "Do not forget to re-define our state as we have a new best-observation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to train the hyper-parameters of the model. This can be done in a similar fashion to a normal PyTorch model.\n",
    "\n",
    "All we need is to define a model and a likelihood, and then activate .train() mode. We then follow classical PyTorch syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define a function that takes as input:\n",
    "1. Training Data\n",
    "2. A TuRBO State\n",
    "\n",
    "And returns the next suggested query! We will define the GP model and optimize the GP's hyper-parameters inside the function itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_query_via_TurBO(train_x, train_y, turbo_state, verbose = True):\n",
    "    # the verbose variable decides wether to print the hyper-parameter optimization details\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "\n",
    "    #for i in range(model.training_iter):\n",
    "    #    # Zero gradients from previous iteration\n",
    "    #    optimizer.zero_grad()\n",
    "    #    # Output from model\n",
    "    #    output = model(train_x)\n",
    "    #    # Calc loss and backprop gradients\n",
    "    #    loss = -mll(output, train_y)\n",
    "    #    loss.backward()\n",
    "    #    if (i % 10 == 9) & verbose:\n",
    "    #        print(f'Iter %d/%d - Loss: %.3f   lengthscale: {model.covar_module.base_kernel.lengthscale}   noise: %.3f' % (\n",
    "    #            i + 1, model.training_iter, loss.item(),\n",
    "    #            model.likelihood.noise.item()\n",
    "    #        ))\n",
    "    #    optimizer.step()\n",
    "    \n",
    "    return generate_batch(turbo_state, model = model, X = train_x, Y = train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can obtain a suggested query!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>student_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f1_output</th>\n",
       "      <th>f2_output</th>\n",
       "      <th>f3_output</th>\n",
       "      <th>f4_output</th>\n",
       "      <th>f5_output</th>\n",
       "      <th>f6_output</th>\n",
       "      <th>f7_output</th>\n",
       "      <th>f8_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>03/05/2024,07:48:46</td>\n",
       "      <td>574</td>\n",
       "      <td>[0.001256,0.001021]</td>\n",
       "      <td>[0.003918,0.999461]</td>\n",
       "      <td>[0.968618,0.009863,0.975288]</td>\n",
       "      <td>[0.005633,0.985666,0.980462,0.996151]</td>\n",
       "      <td>[0.972187,0.993826,0.96857,0.993006]</td>\n",
       "      <td>[0.031377,0.001666,0.983761,0.039847,0.86586,]</td>\n",
       "      <td>[0.091454,0.865694,0.972187,0.993826,0.96857,0...</td>\n",
       "      <td>[0.068548,0.966567,0.010166,0.017496,0.948114,...</td>\n",
       "      <td>6.010000e-247</td>\n",
       "      <td>-0.030595</td>\n",
       "      <td>-0.409314</td>\n",
       "      <td>-45.929543</td>\n",
       "      <td>7364.257265</td>\n",
       "      <td>-2.548909</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>8.975812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>03/05/2024,07:50:03</td>\n",
       "      <td>574</td>\n",
       "      <td>[3.84000e-04,9.99836e-01]</td>\n",
       "      <td>[0.999589,0.001177]</td>\n",
       "      <td>[0.980224,0.987284,0.984398]</td>\n",
       "      <td>[0.022037,0.959062,0.973918,0.998504]</td>\n",
       "      <td>[0.997074,0.019557,0.967915,0.016323]</td>\n",
       "      <td>[0.011266,0.034915,0.985681,0.973807,0.946154]</td>\n",
       "      <td>[0.934126,0.948954,0.940902,0.048562,0.97165,0...</td>\n",
       "      <td>[0.017093,0.872336,0.025212,0.878976,0.9981,0....</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.118484</td>\n",
       "      <td>-0.417066</td>\n",
       "      <td>-44.550293</td>\n",
       "      <td>1348.169270</td>\n",
       "      <td>-2.115151</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>8.594236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>03/05/2024,07:51:27</td>\n",
       "      <td>574</td>\n",
       "      <td>[0.997409,0.002207]</td>\n",
       "      <td>[1.083e-03,7.900e-05]</td>\n",
       "      <td>[0.993846,0.004918,0.978574]</td>\n",
       "      <td>[0.006497,0.001336,0.998308,0.039455]</td>\n",
       "      <td>[0.944327,0.990429,0.003818,0.011438]</td>\n",
       "      <td>[0.96377,0.081122,0.030974,0.009299,0.986679]</td>\n",
       "      <td>[0.080539,0.951776,0.970393,0.126416,0.001409,...</td>\n",
       "      <td>[0.979727,0.034578,0.99476,0.902306,0.697474,0...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>-0.406942</td>\n",
       "      <td>-31.907236</td>\n",
       "      <td>1148.274207</td>\n",
       "      <td>-3.030563</td>\n",
       "      <td>0.070004</td>\n",
       "      <td>5.364045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>07/05/2024,11:28:08</td>\n",
       "      <td>574</td>\n",
       "      <td>[7.09823e-01,1.00000e-06]</td>\n",
       "      <td>[0.999999,0.999999]</td>\n",
       "      <td>[4.36557e-01,9.99999e-01,1.00000e-06]</td>\n",
       "      <td>[0.410877,0.386597,0.384497,0.408079]</td>\n",
       "      <td>[0.999999,0.999999,0.999999,0.999999]</td>\n",
       "      <td>[1.00000e-06,1.21733e-01,1.73952e-01,9.99999e-...</td>\n",
       "      <td>[1.00000e-06,1.00000e-06,2.41238e-01,1.00000e-...</td>\n",
       "      <td>[0.182384,0.376578,0.075565,0.305891,0.497701,...</td>\n",
       "      <td>-1.290000e-182</td>\n",
       "      <td>-0.010824</td>\n",
       "      <td>-0.151982</td>\n",
       "      <td>0.318992</td>\n",
       "      <td>8662.405001</td>\n",
       "      <td>-1.468484</td>\n",
       "      <td>0.408992</td>\n",
       "      <td>9.838246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>07/05/2024,11:37:10</td>\n",
       "      <td>574</td>\n",
       "      <td>[0.997527,0.346407]</td>\n",
       "      <td>[0.00044,0.216108]</td>\n",
       "      <td>[9.38553e-01,7.79000e-04,9.92212e-01]</td>\n",
       "      <td>[0.099045,0.983822,0.983594,0.876675]</td>\n",
       "      <td>[0.446814,0.422643,0.636614,0.692528]</td>\n",
       "      <td>[5.64120e-02,7.21999e-01,9.38553e-01,7.79000e-...</td>\n",
       "      <td>[0.727272,0.326541,0.570444,0.520834,0.961172,...</td>\n",
       "      <td>[2.45056e-01,5.14880e-01,1.00000e-06,2.98890e-...</td>\n",
       "      <td>-4.020000e-151</td>\n",
       "      <td>0.049944</td>\n",
       "      <td>-0.465217</td>\n",
       "      <td>-39.372590</td>\n",
       "      <td>0.889370</td>\n",
       "      <td>-2.582412</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>9.687430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            timestamp  student_id                         f1  \\\n",
       "0           3  03/05/2024,07:48:46         574        [0.001256,0.001021]   \n",
       "1           4  03/05/2024,07:50:03         574  [3.84000e-04,9.99836e-01]   \n",
       "2           5  03/05/2024,07:51:27         574        [0.997409,0.002207]   \n",
       "3          47  07/05/2024,11:28:08         574  [7.09823e-01,1.00000e-06]   \n",
       "4          48  07/05/2024,11:37:10         574        [0.997527,0.346407]   \n",
       "\n",
       "                      f2                                     f3  \\\n",
       "0    [0.003918,0.999461]           [0.968618,0.009863,0.975288]   \n",
       "1    [0.999589,0.001177]           [0.980224,0.987284,0.984398]   \n",
       "2  [1.083e-03,7.900e-05]           [0.993846,0.004918,0.978574]   \n",
       "3    [0.999999,0.999999]  [4.36557e-01,9.99999e-01,1.00000e-06]   \n",
       "4     [0.00044,0.216108]  [9.38553e-01,7.79000e-04,9.92212e-01]   \n",
       "\n",
       "                                      f4  \\\n",
       "0  [0.005633,0.985666,0.980462,0.996151]   \n",
       "1  [0.022037,0.959062,0.973918,0.998504]   \n",
       "2  [0.006497,0.001336,0.998308,0.039455]   \n",
       "3  [0.410877,0.386597,0.384497,0.408079]   \n",
       "4  [0.099045,0.983822,0.983594,0.876675]   \n",
       "\n",
       "                                      f5  \\\n",
       "0   [0.972187,0.993826,0.96857,0.993006]   \n",
       "1  [0.997074,0.019557,0.967915,0.016323]   \n",
       "2  [0.944327,0.990429,0.003818,0.011438]   \n",
       "3  [0.999999,0.999999,0.999999,0.999999]   \n",
       "4  [0.446814,0.422643,0.636614,0.692528]   \n",
       "\n",
       "                                                  f6  \\\n",
       "0     [0.031377,0.001666,0.983761,0.039847,0.86586,]   \n",
       "1     [0.011266,0.034915,0.985681,0.973807,0.946154]   \n",
       "2      [0.96377,0.081122,0.030974,0.009299,0.986679]   \n",
       "3  [1.00000e-06,1.21733e-01,1.73952e-01,9.99999e-...   \n",
       "4  [5.64120e-02,7.21999e-01,9.38553e-01,7.79000e-...   \n",
       "\n",
       "                                                  f7  \\\n",
       "0  [0.091454,0.865694,0.972187,0.993826,0.96857,0...   \n",
       "1  [0.934126,0.948954,0.940902,0.048562,0.97165,0...   \n",
       "2  [0.080539,0.951776,0.970393,0.126416,0.001409,...   \n",
       "3  [1.00000e-06,1.00000e-06,2.41238e-01,1.00000e-...   \n",
       "4  [0.727272,0.326541,0.570444,0.520834,0.961172,...   \n",
       "\n",
       "                                                  f8      f1_output  \\\n",
       "0  [0.068548,0.966567,0.010166,0.017496,0.948114,...  6.010000e-247   \n",
       "1  [0.017093,0.872336,0.025212,0.878976,0.9981,0....   0.000000e+00   \n",
       "2  [0.979727,0.034578,0.99476,0.902306,0.697474,0...   0.000000e+00   \n",
       "3  [0.182384,0.376578,0.075565,0.305891,0.497701,... -1.290000e-182   \n",
       "4  [2.45056e-01,5.14880e-01,1.00000e-06,2.98890e-... -4.020000e-151   \n",
       "\n",
       "   f2_output  f3_output  f4_output    f5_output  f6_output  f7_output  \\\n",
       "0  -0.030595  -0.409314 -45.929543  7364.257265  -2.548909   0.000366   \n",
       "1   0.118484  -0.417066 -44.550293  1348.169270  -2.115151   0.001524   \n",
       "2   0.000554  -0.406942 -31.907236  1148.274207  -3.030563   0.070004   \n",
       "3  -0.010824  -0.151982   0.318992  8662.405001  -1.468484   0.408992   \n",
       "4   0.049944  -0.465217 -39.372590     0.889370  -2.582412   0.007184   \n",
       "\n",
       "   f8_output  \n",
       "0   8.975812  \n",
       "1   8.594236  \n",
       "2   5.364045  \n",
       "3   9.838246  \n",
       "4   9.687430  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions = np.array([i+1 for i in range(8)])\n",
    "functions\n",
    "\n",
    "dimensions = np.array([2,2,3,4,4,5,6,8])\n",
    "dimensions\n",
    "\n",
    "new_points = pd.read_csv('574_data.csv')\n",
    "new_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T1934127\\AppData\\Local\\anaconda3\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next chose query for function 1: [0.630253-0.217094]\n",
      "Next chose query for function 2: [0.889881-0.837831]\n",
      "Next chose query for function 3: [0.565764-0.960095-0.856322]\n",
      "Next chose query for function 4: [0.141256-0.477034-0.282691-0.179128]\n",
      "Next chose query for function 5: [0.995092-0.977907-0.965886-0.950196]\n",
      "Next chose query for function 6: [0.006491-0.223172-0.216323-0.343592-0.261476]\n",
      "Next chose query for function 7: [0.126062-0.419962-0.397820-0.015457-0.021181-0.957438]\n",
      "Next chose query for function 8: [0.321223-0.459460-0.435945-0.416337-0.419268-0.489644-0.615212-0.425271]\n"
     ]
    }
   ],
   "source": [
    "for i in functions:\n",
    "    train_x = torch.from_numpy(np.load('initial_data/function_'+str(i)+'/initial_inputs.npy')).to(torch.float32)\n",
    "    train_y = torch.from_numpy(np.load('initial_data/function_'+str(i)+'/initial_outputs.npy')).to(torch.float32)\n",
    "    train_x_2 = torch.from_numpy(np.load('initial_data2/function_'+str(i)+'/initial_inputs.npy')).to(torch.float32)\n",
    "    train_y_2 = torch.from_numpy(np.load('initial_data2/function_'+str(i)+'/initial_outputs.npy')).to(torch.float32)\n",
    "    \n",
    "    x_new = []\n",
    "    for j in range(len(new_points.index)):\n",
    "        point = np.fromstring(str(new_points['f'+str(i)][j])[1:-1],sep=',')\n",
    "        x_new = np.concatenate((x_new,point),axis=0)\n",
    "\n",
    "    x_new = torch.from_numpy(np.reshape(x_new,(-1,dimensions[i-1])))\n",
    "    x_new\n",
    "    y_new = torch.from_numpy(new_points['f'+str(i)+'_output'].values)\n",
    "    y_new\n",
    "    state = TurboState(dim = dimensions[i-1], best_value = torch.max(train_y).float())\n",
    "    state\n",
    "    train_x = torch.concat((train_x, train_x_2, x_new))\n",
    "    train_x\n",
    "    train_y = torch.concat((train_y, train_y_2, y_new))\n",
    "    train_y\n",
    "    next_query = next_query_via_TurBO(train_x=train_x, train_y=train_y, turbo_state=state)\n",
    "    print(f'Next chose query for function {i}:',np.array2string(next_query.numpy(), precision=6, separator='-', floatmode='fixed',formatter={'float': '{:0.6f}'.format}))\n",
    "    #print('Best X: ',np.array2string(np.array(X_turbo[-1]), precision=6, separator='-', floatmode='fixed',formatter={'float': '{:0.6f}'.format}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6df83ed6fabd41a8e562c5a64e44b5d97b19c29150cbf5eb47fd88445500a37c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
